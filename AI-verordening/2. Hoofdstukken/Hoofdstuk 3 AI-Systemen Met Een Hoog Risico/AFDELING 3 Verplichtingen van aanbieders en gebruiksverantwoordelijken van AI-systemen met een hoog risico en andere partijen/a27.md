## Artikel 27 Beoordeling van de gevolgen voor de grondrechten van [AI-systemen](a3.md#^ai-systeem) met een hoog risico

1. Voordat een [AI-systeem](a3.md#^ai-systeem) met een hoog risico als bedoeld in artikel 6, lid 2, in gebruik wordt gesteld, met uitzondering van [AI-systemen](a3.md#^ai-systeem) met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren [gebruiksverantwoordelijken](a3.md#^gebruiksverantwoordelijke) die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en [gebruiksverantwoordelijken](a3.md#^gebruiksverantwoordelijke) van [AI-systemen](a3.md#^ai-systeem) met een hoog risico als bedoeld in bijlage III, punt 5, b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren. Daartoe voeren [gebruiksverantwoordelijken](a3.md#^gebruiksverantwoordelijke) een beoordeling uit die bestaat uit:
	1. a) een beschrijving van de processen van de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) waarbij het [AI-systeem](a3.md#^ai-systeem) met een hoog risico zal worden gebruikt in overeenstemming met het beoogde doel ervan;
	2. b) een beschrijving van de periode waarbinnen en de frequentie waarmee elk [AI-systeem](a3.md#^ai-systeem) met een hoog risico zal worden gebruikt;
	3. c) categorieën van natuurlijke personen en groepen die naar verwachting gevolgen zullen ondervinden van het gebruik van het systeem in een specifieke context;
	4. d) de specifieke risico’s op schade die waarschijnlijk gevolgen zullen hebben voor de op grond van punt c) van dit lid geïdentificeerde categorieën natuurlijke personen of groepen personen, rekening houdend met de door de aanbieder op grond van artikel 13 verstrekte informatie;
	5. e) een beschrijving van de uitvoering van maatregelen voor menselijk toezicht, overeenkomstig de gebruiksaanwijzing;
	6. f) de maatregelen die moeten worden genomen wanneer die risico’s zich voordoen, met inbegrip van de regelingen voor interne governance en klachtenregelingen.
2. De verplichting als neergelegd in lid 1 is van toepassing op het eerste gebruik van een [AI-systeem](a3.md#^ai-systeem) met een hoog risico. De [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) kan in soortgelijke gevallen gebruik maken van eerder uitgevoerde effectbeoordelingen op het gebied van de grondrechten of bestaande effectbeoordelingen die door de aanbieder zijn uitgevoerd. Indien de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) tijdens het gebruik van het [AI-systeem](a3.md#^ai-systeem) met een hoog risico ziet dat een van de in lid 1 vermelde elementen is gewijzigd of niet langer actueel is, neemt de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) de nodige maatregelen om de informatie te actualiseren.
3. Zodra de in lid 1 van dit artikel bedoelde beoordeling is uitgevoerd, stelt de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) de [markttoezichtautoriteit](a3.md#^mta) in kennis van de resultaten ervan, en dient hij als onderdeel van de kennisgeving het in lid 5 van dit artikel bedoelde ingevulde sjabloon in. In het in artikel 46, lid 1, bedoelde geval kunnen [gebruiksverantwoordelijken](a3.md#^gebruiksverantwoordelijke) van de verplichting tot kennisgeving worden vrijgesteld.
4. Indien een van de in dit artikel vastgelegde verplichtingen reeds is nagekomen door de gegevensbeschermingseffectbeoordeling die is uitgevoerd op grond van artikel 35 van Verordening (EU) 2016/679 of artikel 27 van Richtlijn (EU) 2016/680, vormt de in lid 1 van dit artikel bedoelde effectbeoordeling op het gebied van de grondrechten een aanvulling op die gegevensbeschermingseffectbeoordeling.
5. Het [AI-bureau](a3.md#^aibur) ontwikkelt een sjabloon voor een vragenlijst, onder meer via een geautomatiseerd instrument, om [gebruiksverantwoordelijken](a3.md#^gebruiksverantwoordelijke) te helpen hun verplichtingen uit hoofde van dit artikel op vereenvoudigde wijze na te komen.