---
layout: page
title: "AFDELING 4 Aanmeldende autoriteiten en [aangemelde instantie](a3.md#^aanins) s"
---

## Artikel 15 Nauwkeurigheid, robuustheid en cyberbeveiliging

1. [AI-systemen](a3.md#^ai-systeem) met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente [prestaties](a3.md#^prestaties) gedurende de levensduur met betrekking tot deze aspecten.
2. Ter verduidelijking van de technische aspecten van de meting van het passende niveau van nauwkeurigheid en robuustheid als bedoeld in lid 1 en andere relevante [prestaties](a3.md#^prestaties)tatistieken, moedigt de Commissie, in samenwerking met relevante belanghebbenden en organisaties, zoals metrologie- en benchmarkingautoriteiten, waar passend, de ontwikkeling van benchmarks en meetmethoden aan.
3. De niveaus van nauwkeurigheid en de relevante maatstaven voor de nauwkeurigheid van [AI-systemen](a3.md#^ai-systeem) met een hoog risico worden vermeld in de bijbehorende gebruiksaanwijzingen.
4. [AI-systemen](a3.md#^ai-systeem) met een hoog risico zijn zo goed mogelijk bestand tegen fouten en onregelmatigheden die zich binnen het systeem of de omgeving waarin het systeem wordt gebruikt, kunnen voordoen, met name als gevolg van de interactie ervan met natuurlijke personen of andere systemen. In dat opzicht worden technische en organisatorische maatregelen genomen.
   De robuustheid van [AI-systemen](a3.md#^ai-systeem) met een hoog risico kan worden gerealiseerd door middel van technische oplossingen voor redundantie, die plannen voor de back-up of de veiligheid bij defecten kunnen omvatten.
   [AI-systemen](a3.md#^ai-systeem) met een hoog risico die blijven leren nadat ze in de handel zijn gebracht of in gebruik zijn gesteld, worden op zodanige wijze ontwikkeld dat het risico op beïnvloeding van toekomstige operaties door gebruik van vertekende outputs als input (“feedback loops”) wordt weggenomen of zo veel mogelijk worden beperkt en dat elke dergelijke feedback loop naar behoren wordt aangepakt met behulp van passende beperkende maatregelen.
5. [AI-systemen](a3.md#^ai-systeem) met een hoog risico zijn bestand tegen pogingen van ongeautoriseerde derden om het gebruik, de outputs of de [prestaties](a3.md#^prestaties) ervan te wijzigen door gebruik te maken van de kwetsbaarheden van het systeem.
   De technische oplossingen die gericht zijn op het waarborgen van de cyberbeveiliging van [AI-systemen](a3.md#^ai-systeem) met een hoog risico sluiten aan op de relevante omstandigheden en risico’s.
   De technische oplossingen voor het aanpakken van AI-specifieke kwetsbaarheden omvatten, waar passend, maatregelen voor het voorkomen, traceren, reageren op, oplossen en beheersen van aanvallen waarmee een poging wordt gedaan tot het manipuleren van de dataset voor de training (de zogenaamde “datavervuiling”), van vooraf getrainde componenten die in de training zijn gebruikt (de zogenaamde “modelvervuiling”), van input die is gecreëerd om fouten van het model te veroorzaken (zogenaamde “vijandige voorbeelden” of “modelontwijking”), van aanvallen om vertrouwelijke gegevens te bemachtigen of van tekortkomingen van het model.

# AFDELING 4 Aanmeldende autoriteiten en [aangemelde instantie](a3.md#^aanins) s