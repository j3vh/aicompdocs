## Artikel 14 Menselijk toezicht

1. [AI-systemen](a3.md#^ai-systeem) met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.
2. Het menselijk toezicht is gericht op het voorkomen of beperken van de risico’s voor de gezondheid, veiligheid of grondrechten die zich kunnen voordoen wanneer een [AI-systeem](a3.md#^ai-systeem) met een hoog risico wordt gebruikt in overeenstemming met het beoogde doel ervan of in een situatie van [redelijkerwijs te voorzien misbruik](a3.md#^vzmisbruik), met name wanneer dergelijke risico’s blijven bestaan ondanks de toepassing van andere eisen van deze afdeling.
3. De toezichtmaatregelen staan in verhouding met de risico’s, de mate van autonomie en de gebruikscontext van het [AI-systeem](a3.md#^ai-systeem) met een hoog risico en worden gewaarborgd door middel van een of alle van de volgende soorten maatregelen:
	1. a) door de aanbieder bepaalde maatregelen die waar technisch haalbaar in het [AI-systeem](a3.md#^ai-systeem) met een hoog risico worden ingebouwd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld;
	2. b) door de aanbieder bepaalde maatregelen voordat het [AI-systeem](a3.md#^ai-systeem) met een hoog risico in de handel wordt gebracht of in gebruik wordt gesteld en die passend zijn om door de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) te worden uitgevoerd.
4. Met het oog op de uitvoering van de leden 1, 2 en 3 wordt het [AI-systeem](a3.md#^ai-systeem) met een hoog risico zodanig aan de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) verstrekt dat natuurlijke personen die verantwoordelijk zijn voor het menselijk toezicht, in staat worden gesteld om waar passend en evenredig:
	1. a) de relevante capaciteiten en beperkingen van het [AI-systeem](a3.md#^ai-systeem) met een hoog risico goed te begrijpen en de werking ervan naar behoren te kunnen monitoren, onder meer met het oog op het opsporen en aanpakken van onregelmatigheden, storingen en onverwachte [prestaties](a3.md#^prestaties);
	2. b) zich bewust te blijven van de mogelijke neiging om automatisch of te veel te vertrouwen op de output van een [AI-systeem](a3.md#^ai-systeem) met een hoog risico (de zogenaamde “automation bias”), met name voor [AI-systemen](a3.md#^ai-systeem) met een hoog risico die worden gebruikt om informatie of aanbevelingen te verstrekken voor beslissingen die door natuurlijke personen moeten worden genomen;
	3. c) de output van het [AI-systeem](a3.md#^ai-systeem) met een hoog risico juist te interpreteren, bijvoorbeeld de beschikbare instrumenten en methoden voor interpretatie;
	4. d) in alle specifieke situaties te kunnen besluiten om het [AI-systeem](a3.md#^ai-systeem) met een hoog risico niet te gebruiken of de output van het [AI-systeem](a3.md#^ai-systeem) met een hoog risico op andere wijze te negeren, door een andere beslissing te vervangen of terug te draaien;
	5. e) in te grijpen in de werking van het [AI-systeem](a3.md#^ai-systeem) met een hoog risico of het systeem te onderbreken door middel van een stopknop of een vergelijkbare procedure waarmee het systeem op veilige wijze kan worden stopgezet.
5. Voor [AI-systemen](a3.md#^ai-systeem) met een hoog risico als bedoeld in bijlage III, punt 1, a), zijn de maatregelen als bedoeld in lid 3 van dit artikel zodanig dat zij waarborgen dat daarnaast door de [gebruiksverantwoordelijke](a3.md#^gebruiksverantwoordelijke) geen maatregelen worden getroffen of beslissingen worden genomen op basis van de identificatie door het systeem, tenzij deze identificatie door ten minste twee natuurlijke personen met de nodige bekwaamheid, opleiding en bevoegdheid apart zijn geverifieerd en bevestigd.
Het vereiste van een afzonderlijke verificatie door ten minste twee natuurlijke personen is niet van toepassing op [AI-systemen](a3.md#^ai-systeem) met een hoog risico die gebruikt worden voor rechtshandhaving, migratie, grenstoezicht of asiel, in gevallen waarin het Unierecht of het nationale recht de toepassing van dit vereiste onevenredig acht.