(27)

Hoewel de risicogebaseerde aanpak de basis vormt voor een evenredige en doeltreffende reeks bindende regels, is het belangrijk te herinneren aan de ethische richtsnoeren voor betrouwbare KI van 2019 die zijn opgesteld door de onafhankelijke AI HLEG die door de Commissie is aangesteld. In die richtsnoeren heeft de AI HLEG zeven niet-bindende ethische beginselen ontwikkeld die ervoor moeten zorgen dat AI betrouwbaar en ethisch verantwoord is. Die beginselen zijn: invloed en toezicht door mensen, technische robuustheid en veiligheid, privacy en datagovernance, transparantie; diversiteit, non-discriminatie en rechtvaardigheid, sociaal en ecologisch welzijn, en verantwoordingsplicht. Onverminderd de juridisch bindende eisen van deze verordening en enig ander toepasselijk Unierecht dragen die richtsnoeren bij tot het ontwerpen van coherente, betrouwbare en mensgerichte AI, in overeenstemming met het Handvest en de waarden waarop de Unie is gegrondvest. Volgens de richtsnoeren van de AI HLEG houdt “invloed en toezicht door mensen” in dat [AI-systemen](a3.md#^ai-systeem) worden ontwikkeld en gebruikt als een instrument dat ten dienste staat van mensen, dat de menselijke waardigheid en persoonlijke autonomie eerbiedigt, en dat functioneert op een wijze waar mensen op passende wijze controle en toezicht op kunnen houden. “Technische robuustheid en veiligheid” betekent dat [AI-systemen](a3.md#^ai-systeem) worden ontwikkeld op een wijze die voorziet in robuustheid in geval van problemen en in weerbaarheid tegen pogingen om het gebruik of de [prestaties](a3.md#^prestaties) van het [AI-systeem](a3.md#^ai-systeem) te wijzigen voor onrechtmatig gebruik door derden, en die onbedoelde schade tot een minimum beperkt. “Privacy en datagovernance” betekent dat [AI-systemen](a3.md#^ai-systeem) worden ontwikkeld en gebruikt in overeenstemming met de regels inzake privacy en gegevensbescherming, en de verwerking van gegevens voldoet aan hoge normen wat kwaliteit en integriteit betreft. “Transparantie” betekent dat [AI-systemen](a3.md#^ai-systeem) worden ontwikkeld en gebruikt op een wijze die passende traceerbaarheid en verklaarbaarheid mogelijk maakt, waarbij mensen ervan bewust worden gemaakt dat zij communiceren of interageren met een [AI-systeem](a3.md#^ai-systeem), en [gebruiksverantwoordelijken](a3.md#^gebruiksverantwoordelijke) naar behoren worden geïnformeerd over de mogelijkheden en beperkingen van dat [AI-systeem](a3.md#^ai-systeem) en betrokken personen worden geïnformeerd over hun rechten. “Diversiteit, non-discriminatie en rechtvaardigheid” betekent dat [AI-systemen](a3.md#^ai-systeem) zodanig worden ontwikkeld en gebruikt dat de inclusie van diverse actoren wordt gewaarborgd en dat gelijke toegang, gendergelijkheid en culturele diversiteit worden bevorderd, waarbij discriminerende effecten en onrechtvaardige vertekeningen die op grond van het Unierecht of het nationale recht verboden zijn, worden voorkomen. “Sociaal en ecologisch welzijn” betekent dat [AI-systemen](a3.md#^ai-systeem) worden ontwikkeld en gebruikt op een duurzame en milieuvriendelijke wijze en op een manier die alle mensen ten goede komt, waarbij de langetermijneffecten op het individu, de samenleving en de democratie worden gemonitord en beoordeeld. De toepassing van die beginselen moet waar mogelijk worden vertaald in het ontwerp en het gebruik van AI-modellen. Zij moeten in ieder geval dienen als basis voor het opstellen van gedragscodes in het kader van deze verordening. Alle belanghebbenden, met inbegrip van het bedrijfsleven, de academische wereld, het maatschappelijk middenveld en normalisatieorganisaties, worden aangemoedigd om in voorkomend geval rekening te houden met de ethische beginselen voor de ontwikkeling van vrijwillige beste praktijken en normen.