(53)

Het is ook belangrijk te verduidelijken dat er specifieke gevallen kunnen zijn waarin [AI-systemen](a3.md#^ai-systeem) die worden gebruikt op in deze verordening beschreven, specifieke gebieden, niet leiden tot een aanzienlijk risico op schade aan de juridische belangen die op die gebieden worden beschermd, omdat zij de besluitvorming niet wezenlijk beïnvloeden of die belangen niet wezenlijk schaden. Voor de toepassing van deze verordening moet een [AI-systeem](a3.md#^ai-systeem) dat het resultaat van de besluitvorming niet wezenlijk beïnvloedt, worden beschouwd als een [AI-systeem](a3.md#^ai-systeem) dat geen invloed heeft op de inhoud, en daarmee op het resultaat, van de menselijke of geautomatiseerde besluitvorming. Er kan sprake zijn van een [AI-systeem](a3.md#^ai-systeem) dat het resultaat van de besluitvorming niet wezenlijk beïnvloedt, indien aan een of meer van de volgende voorwaarden is voldaan. De eerste voorwaarde luidt dat het [AI-systeem](a3.md#^ai-systeem) bedoeld moet zijn om een enge procedurele taak uit te voeren, zoals een [AI-systeem](a3.md#^ai-systeem) dat ongestructureerde data omzet in gestructureerde data, een [AI-systeem](a3.md#^ai-systeem) dat binnenkomende documenten classificeert in categorieën of een [AI-systeem](a3.md#^ai-systeem) dat wordt gebruikt om binnen een groot aantal aanvragen dubbels op te sporen. Dergelijke taken zijn dermate specifiek en beperkt dat zij slechts beperkte risico’s met zich meebrengen, die niet toenemen door gebruik van een [AI-systeem](a3.md#^ai-systeem) in een context die in een bijlage bij deze verordening als gebruik met een hoog risico is opgenomen. De tweede voorwaarde is dat de door het [AI-systeem](a3.md#^ai-systeem) uitgevoerde taak bedoeld moet zijn om het resultaat te verbeteren van een eerder voltooide menselijke activiteit die relevant kan zijn in voor de in een lijst in een bijlage bij deze verordening vermelde gevallen van hoog-risicogebruik. Die kenmerken in beschouwing genomen, voegt het [AI-systeem](a3.md#^ai-systeem) slechts een extra laag toe aan een menselijke activiteit, en houdt dit bijgevolg een lager risico in. Dit is bijvoorbeeld het geval voor [AI-systemen](a3.md#^ai-systeem) die bedoeld zijn om de taal van eerder opgestelde documenten te verbeteren, bijvoorbeeld met betrekking tot professionele toon of academische stijl, of door een tekst af te stemmen op een bepaalde merkboodschap. Als derde voorwaarde geldt dat het [AI-systeem](a3.md#^ai-systeem) bedoeld moet zijn om besluitvormings-patronen of afwijkingen van eerdere besluitvormingspatronen op te sporen. Het risico zou in dergelijke gevallen lager liggen omdat het [AI-systeem](a3.md#^ai-systeem) wordt gebruikt na een eerder afgeronde menselijke beoordeling en het niet de bedoeling is dat het [AI-systeem](a3.md#^ai-systeem) deze vervangt of wijzigt zonder gedegen menselijke toetsing. Dergelijke [AI-systemen](a3.md#^ai-systeem) omvatten bijvoorbeeld systemen die, aan de hand van een bepaald beoordelingspatroon van een leerkracht, achteraf kunnen worden gebruikt om na te gaan of de leerkracht mogelijk van dat patroon is afgeweken, en zo mogelijke inconsistenties of anomalieën te signaleren. De vierde voorwaarde houdt in dat het [AI-systeem](a3.md#^ai-systeem) bedoeld moet zijn om een taak uit te voeren die slechts dient ter voorbereiding van een beoordeling die relevant is voor de in een bijlage bij deze verordening vermelde [AI-systemen](a3.md#^ai-systeem), waardoor het mogelijke effect van de output van het systeem een zeer laag risico inhoudt voor de beoordeling die erop volgt. Daarbij kan het onder meer gaan over slimme oplossingen voor bestandsbeheer, waaronder verschillende functies zoals indexering, opzoeking, tekst- en spraakverwerking of het koppelen van gegevens aan andere gegevensbronnen, of [AI-systemen](a3.md#^ai-systeem) die worden gebruikt voor de vertaling van brondocumenten. In elk geval moeten [AI-systemen](a3.md#^ai-systeem) die worden gebruikt in een bijlage bij deze verordening vermelde gevallen van gebruik met een hoog risico worden geacht een aanzienlijk risico te vormen op schade aan de gezondheid, veiligheid of grondrechten indien het [AI-systeem](a3.md#^ai-systeem) [profilering](a3.md#^profil) inhoudt in de zin van artikel 4, punt 4), van Verordening (EU) 2016/679 of artikel 3, punt 4), van Richtlijn (EU) 2016/680 of artikel 3, punt 5), van Verordening (EU) 2018/1725. Om de traceerbaarheid en transparantie te waarborgen, moet een aanbieder die op basis van de hierboven vermelde voorwaarden van mening is dat een [AI-systeem](a3.md#^ai-systeem) geen hoog risico vormt, documentatie van de beoordeling opstellen voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld, en moet hij deze documentatie op verzoek aan de [nationale bevoegde autoriteit](a3.md#^natbau)en verstrekken. Een dergelijke aanbieder moet worden verplicht het [AI-systeem](a3.md#^ai-systeem) te registreren in de EU-databank die bij deze verordening wordt opgezet. Met het oog op het verstrekken van verdere richtsnoeren voor de praktische uitvoering van de voorwaarden waaronder de in een bijlage bij deze verordening vermelde [AI-systemen](a3.md#^ai-systeem) bij wijze van uitzondering geen hoog risico vormen, moet de Commissie, na raadpleging van de AI-board, richtsnoeren verstrekken waarin die praktische uitvoering wordt uiteengezet, aangevuld met een uitgebreide lijst van praktische voorbeelden van gebruiksgevallen van [AI-systemen](a3.md#^ai-systeem) met een hoog risico en van gebruiksgevallen van [AI-systemen](a3.md#^ai-systeem) zonder hoog risico.