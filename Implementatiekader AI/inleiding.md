---
title: Inleiding
layout: default
parent: Implementatiekader AI
grand_parent: Volledige tekst
---

## **Aanleiding**

De inzet van algoritmen biedt kansen en mogelijkheden bij de aanpak van maatschappelijke opgaven en de uitvoering van publieke taken. Maar wanneer de overheid een algoritme in een verkeerde context, op een verkeerde manier, of met een verkeerd doel inzet, dan kan de negatieve impact voor burgers groot zijn. Publieke waarden en fundamentele rechten zoals privacy, non-discriminatie, autonomie en menselijke waardigheid kunnen – soms ten opzichte van elkaar - onder druk komen te staan waardoor burgers, maar ook bedrijven, in de knel kunnen komen.

Inzet van algoritmen moet daarom verantwoord zijn. Dat wil zeggen dat de inzet wettig, ethisch en robuust is. Daarom wordt onder andere gewerkt aan Europese wetgeving die eisen stelt aan AI-systemen ter bescherming van mensenrechten en die ervoor moet zorgen dat het handelen van dergelijke systemen in overeenstemming is met publieke waarden. Maar ook op dit moment gelden al wettelijke verplichtingen voor de inzet van algoritmen en instrumenten om hierbij te ondersteunen, zoals handreikingen en best practices. Deze zien bijvoorbeeld op de maatschappelijke en ethische aspecten van het gebruik van algoritmen.

Om tot een verdere borging te komen van de verantwoorde inzet van algoritmen binnen de overheid is het belangrijk dat duidelijk is hoe overheidsorganisaties in de praktijk invulling kunnen geven aan hun verplichtingen, en welke instrumenten daarbij beschikbaar zijn. Het Implementatiekader ‘Verantwoorde inzet van algoritmen’ zal hier duidelijkheid in bieden. Deze eerste versie van het implementatiekader is hiertoe de eerste aanzet.

## **Doel en scope**

Dit implementatiekader heeft tot doel overheden te ondersteunen bij de verantwoorde inzet van algoritmen. Daartoe biedt het een overzicht van de belangrijkste normen en maatregelen bij de ontwikkeling en implementatie van algoritmen. Het implementatiekader richt zich in deze eerste versie op het bieden van overzicht in de belangrijkste generieke aspecten waarmee rekening moet worden gehouden bij de inzet van algoritmen, en de verplichtingen en richtlijnen die zich lenen voor algemene brede toepassing. Het implementatiekader is daarmee niet alomvattend. Domeinspecifieke toepassingen kennen aanvullende verplichtingen die niet allemaal te vatten zijn in één kader. Dit geldt bijvoorbeeld voor de zorg. Voor de politie en andere rechtshandhavingsautoriteiten gelden voor een deel afwijkende normen. Deze specifieke normen zijn niet opgenomen in deze versie van het implementatiekader.

Het implementatiekader is geen 'checklist'. Het nemen van de maatregelen in dit kader leidt veelal niet rechtstreeks tot het voldoen aan een verplichting en niet alle maatregelen in dit kader zijn verplicht. Gebruikers van dit implementatiekader zullen dus tot een eigen afweging komen. Waar nodig zullen zij ook aanvullend advies moeten vragen, bijvoorbeeld bij waardenspanningen en ethische dilemma’s.

Binnen de Rijksoverheid ligt de verantwoordelijkheid voor het identificeren en beheersen van risico's op het gebied van algoritmetoepassingen op een specifiek beleidsterrein primair bij het betreffende ministerie. Samen met de ministeries geeft CIO Rijk ook vorm aan een interne toezichtstructuur waarin de rollen van de verschillende lines of defense worden vormgegeven. De verschillende lines of defense zorgen voor meerdere controlepunten in het toezicht op algoritmen. De toezichtstructuur zal ook worden beschreven in de volgende fase van het implementatiekader. Daarbij zal ook in worden gegaan op de manier waarop dit binnen gemeentes, provincies en waterschappen kan worden vormgegeven.

De Directie Coördinatie Algoritmes (DCA) van de Autoriteit Persoonsgegevens fungeert als externe algoritmetoezichthouder. De DCA faciliteert en ondersteunt het uniform uitleggen van (domeinoverstijgende) normen die betrekking hebben op algoritme-inzet in samenwerking met andere toezichthouders. Voor ondertoezichtgestelden – bijvoorbeeld burgers, bedrijven of overheden – is het onder meer in het kader van rechtsbescherming en de voorspelbaarheid van het overheidshandelen belangrijk dat zij weten aan welke normen zij moeten voldoen

De Auditdienst Rijk (ADR) brengt al regelmatig uit over algoritmegebruik binnen de Rijksdienst en het toezicht hierop. Ook de Algemene Rekenkamer kan op eigen initiatief onderzoeken starten naar algoritmegebruik bij de (Rijks)-overheid. Daarnaast is hier de rol van de Rijksinspecties, die in hun toezicht ook algoritmes tegenkomen, relevant.

De doelgroep van het implementatiekader is de gehele overheid (Rijk, provincies, gemeenten en waterschappen). Het implementatiekader is er voor iedereen binnen de overheid, maar richt zich met name op de mensen die betrokken zijn bij de ontwikkeling, implementatie, toetsing en verantwoording van algoritmen.

## **Uitgangspunt: Publieke waarden, mensenrechten en ethische principes**

Het verantwoord inzetten van algoritmen betekent dat de inzet wettig, ethisch en robuust is. Dit betekent dat ten minste voldaan moet worden aan wet- en regelgeving en dat de inzet in lijn is met publieke waarden en ethische principes.

Het implementatiekader neemt dit dan ook als uitgangspunt. Voor de structuur is aangesloten op de ethische richtsnoeren die mede ten grondslag liggen aan de AI Verordening. Deze richtsnoeren omvatten belangrijke publieke waarden zoals menselijke controle, rechtvaardigheid, privacy en non-discriminatie. Aan de hand van deze thema’s zijn de belangrijkste bestaande verplichtingen en richtlijnen in kaart gebracht, en worden maatregelen en waarborgen aangereikt.  De wijze waarop deze governance (waaronder een heldere verdeling van bevoegdheden en verantwoordelijkheden) binnen de overheid invulling krijgt is nog onderwerp van gesprek, en wordt zoals aangegeven meegenomen in de verdere doorontwikkeling van het implementatiekader.

## **Totstandkoming, doorontwikkeling en betrokkenen**

Het implementatiekader bouwt voort op onder andere het Toetsingskader Algoritmen van de Algemene Rekenkamer (ARK) en het normenkader zoals gebruikt door de Auditdienst Rijk (ADR). Daarnaast is gebruik gemaakt van de inzichten en elementen uit onder andere het Impact Assessment Mensenrechten Algoritmen (IAMA), de Handreiking non-discriminatie by design, de Ethische Richtsnoeren voor betrouwbare AI en het toetsingskader van het College voor de Rechten van de Mens “Discriminatie door risicoprofielen, een mensenrechtelijk Toetsingskader"

De versie die voorligt is een eerste versie. Het implementatiekader is een ‘levend’ document. Het zal worden doorontwikkeld langs een aantal lijnen:

1. Actualisatie: het IKA zal (te allen tijde) worden geactualiseerd op basis van suggesties voor verbeteringen, nieuwe normenkaders of wetgeving (b.v. AI-Verordening). Dit is een doorlopend proces.
2. Het IKA zal in een volgende versie worden uitgebreid met best practices en hulpmiddelen op het gebied van de inzet van algoritmen (b.v. via bestaande of te ontwikkelen handreikingen) waarbij wordt gekeken naar bruikbaarheid en uitvoerbaarheid.
3. Organisatorische inbedding: in een volgende fase van de doorontwikkeling wordt meer inzicht gegeven in hoe de governance rondom algoritmen kan worden ingericht, dus op welke wijze de normen, toetsingskaders en wetgeving op het gebied van algoritmen kunnen worden ingebed in de organisatie. Het IKA zal in de volgende fase van de doorontwikkeling ook dieper ingaan op de wijze waarop controle en toezicht zijn georganiseerd. Ook deze fase zal in het eerste kwartaal van 2024 afgerond zijn.

De doorontwikkeling vindt plaats in nauwe afstemming met experts en (interbestuurlijke) betrokkenen. Op die manier draagt het implementatiekader bij aan de naleving van wettelijke verplichtingen en het handelen in overeenstemming met publieke waarden.

## Leeswijzer

In hoofdstuk 2 worden de begrippen algoritme en AI nader uitgelegd om richting te geven aan het gebruik van dit implementatiekader. Daarbij wordt ook ingegaan op de samenhang van dit kader met de aanstaande AI-verordening. Het implementatiekader bestaat vervolgens uit twee delen (zie ook figuur 1):

1. Een overzicht van normen en maatregelen bij de inzet van algoritmen op basis van de belangrijkste verplichtingen en richtlijnen in hoofdstuk 3.
2. De inbedding in de organisatie waarbij in hoofdstuk 4 wordt ingegaan op de organisatie en de omgevingsfactoren die bijdragen aan de borging van verantwoord gebruik van algoritmen.

In de bijlage is daarnaast een eerste overzicht gegeven van relevante instrumenten - zoals handreikingen en assessments - als aanzet voor de verdere ontwikkeling van het implementatiekader.

*Figuur 1 Schematische weergave van de verantwoorde inzet van algoritmen*